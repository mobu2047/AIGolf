#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ ¼å¼è½¬æ¢å·¥å…·
å°†COCOæ ¼å¼ã€Pascal VOCæ ¼å¼ç­‰è½¬æ¢ä¸ºYOLOæ ¼å¼
"""

import json
import cv2
import numpy as np
import shutil
import xml.etree.ElementTree as ET
from pathlib import Path
import argparse
from tqdm import tqdm

class DatasetConverter:
    """æ•°æ®é›†æ ¼å¼è½¬æ¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        self.supported_formats = ['coco', 'voc', 'yolo']
        print("ğŸ”„ æ•°æ®é›†æ ¼å¼è½¬æ¢å™¨å·²åˆå§‹åŒ–")
    
    def convert_dataset(self, input_dir, output_dir, input_format, output_format='yolo'):
        """
        è½¬æ¢æ•°æ®é›†æ ¼å¼
        
        Args:
            input_dir: è¾“å…¥æ•°æ®é›†ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            input_format: è¾“å…¥æ ¼å¼ ('coco', 'voc', 'yolo')
            output_format: è¾“å‡ºæ ¼å¼ (ç›®å‰åªæ”¯æŒ'yolo')
        """
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        
        if not input_path.exists():
            raise ValueError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        
        if input_format not in self.supported_formats:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥æ ¼å¼: {input_format}")
        
        print(f"ğŸ”„ å¼€å§‹è½¬æ¢: {input_format.upper()} -> {output_format.upper()}")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_path}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self._create_yolo_structure(output_path)
        
        # æ ¹æ®è¾“å…¥æ ¼å¼é€‰æ‹©è½¬æ¢æ–¹æ³•
        if input_format == 'coco':
            self._convert_from_coco(input_path, output_path)
        elif input_format == 'voc':
            self._convert_from_voc(input_path, output_path)
        elif input_format == 'yolo':
            self._copy_yolo_dataset(input_path, output_path)
        
        # ç”ŸæˆYOLOé…ç½®æ–‡ä»¶
        self._generate_yolo_config(output_path)
        
        print("âœ… æ•°æ®é›†è½¬æ¢å®Œæˆ!")
    
    def _create_yolo_structure(self, output_path):
        """åˆ›å»ºYOLOæ ¼å¼çš„ç›®å½•ç»“æ„"""
        directories = [
            output_path / "images" / "train",
            output_path / "images" / "val",
            output_path / "labels" / "train", 
            output_path / "labels" / "val"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ å·²åˆ›å»ºYOLOç›®å½•ç»“æ„")
    
    def _convert_from_coco(self, input_path, output_path):
        """ä»COCOæ ¼å¼è½¬æ¢"""
        print("ğŸ”„ æ­£åœ¨ä»COCOæ ¼å¼è½¬æ¢...")
        
        # æŸ¥æ‰¾COCOæ ‡æ³¨æ–‡ä»¶
        annotation_files = list(input_path.glob("**/*.json"))
        
        if not annotation_files:
            # å°è¯•æŸ¥æ‰¾æ ‡å‡†COCOç»“æ„
            for split in ['train', 'val', 'test']:
                ann_file = input_path / 'annotations' / f'instances_{split}.json'
                if ann_file.exists():
                    annotation_files.append(ann_file)
        
        if not annotation_files:
            raise ValueError("æœªæ‰¾åˆ°COCOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶")
        
        total_converted = 0
        
        for ann_file in annotation_files:
            print(f"ğŸ“„ å¤„ç†æ ‡æ³¨æ–‡ä»¶: {ann_file.name}")
            
            # ç¡®å®šåˆ†å‰²ç±»å‹
            if 'train' in ann_file.name.lower():
                split = 'train'
            elif 'val' in ann_file.name.lower():
                split = 'val'
            else:
                split = 'train'  # é»˜è®¤ä¸ºè®­ç»ƒé›†
            
            converted_count = self._convert_coco_file(ann_file, input_path, output_path, split)
            total_converted += converted_count
        
        print(f"âœ… COCOè½¬æ¢å®Œæˆï¼Œå…±è½¬æ¢ {total_converted} ä¸ªæ ·æœ¬")
    
    def _convert_coco_file(self, ann_file, input_path, output_path, split):
        """è½¬æ¢å•ä¸ªCOCOæ ‡æ³¨æ–‡ä»¶"""
        with open(ann_file, 'r', encoding='utf-8') as f:
            coco_data = json.load(f)
        
        # åˆ›å»ºå›¾åƒIDåˆ°æ–‡ä»¶åçš„æ˜ å°„
        image_id_to_filename = {}
        image_id_to_size = {}
        
        for image_info in coco_data.get('images', []):
            image_id_to_filename[image_info['id']] = image_info['file_name']
            image_id_to_size[image_info['id']] = (image_info['width'], image_info['height'])
        
        # æŒ‰å›¾åƒåˆ†ç»„æ ‡æ³¨
        annotations_by_image = {}
        for annotation in coco_data.get('annotations', []):
            image_id = annotation['image_id']
            if image_id not in annotations_by_image:
                annotations_by_image[image_id] = []
            annotations_by_image[image_id].append(annotation)
        
        converted_count = 0
        
        # è½¬æ¢æ¯ä¸ªå›¾åƒ
        for image_id, annotations in tqdm(annotations_by_image.items(), desc=f"è½¬æ¢{split}é›†"):
            if image_id not in image_id_to_filename:
                continue
            
            filename = image_id_to_filename[image_id]
            img_width, img_height = image_id_to_size[image_id]
            
            # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
            image_path = self._find_image_file(input_path, filename)
            if not image_path:
                print(f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {filename}")
                continue
            
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            target_img_path = output_path / "images" / split / filename
            shutil.copy2(image_path, target_img_path)
            
            # è½¬æ¢æ ‡æ³¨
            yolo_annotations = []
            for annotation in annotations:
                yolo_line = self._convert_coco_annotation_to_yolo(annotation, img_width, img_height)
                if yolo_line:
                    yolo_annotations.append(yolo_line)
            
            # ä¿å­˜YOLOæ ‡æ³¨æ–‡ä»¶
            if yolo_annotations:
                label_filename = Path(filename).stem + '.txt'
                label_path = output_path / "labels" / split / label_filename
                
                with open(label_path, 'w') as f:
                    f.write('\n'.join(yolo_annotations) + '\n')
                
                converted_count += 1
        
        return converted_count
    
    def _convert_coco_annotation_to_yolo(self, annotation, img_width, img_height):
        """å°†å•ä¸ªCOCOæ ‡æ³¨è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        if 'bbox' not in annotation:
            return None
        
        # COCO bboxæ ¼å¼: [x, y, width, height]
        x, y, w, h = annotation['bbox']
        
        # è½¬æ¢ä¸ºYOLOæ ¼å¼ (å½’ä¸€åŒ–çš„ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜)
        x_center = (x + w / 2) / img_width
        y_center = (y + h / 2) / img_height
        norm_width = w / img_width
        norm_height = h / img_height
        
        # ç±»åˆ«ID (å‡è®¾çƒæ†ç±»åˆ«ä¸º0)
        class_id = 0
        
        return f"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}"
    
    def _convert_from_voc(self, input_path, output_path):
        """ä»Pascal VOCæ ¼å¼è½¬æ¢"""
        print("ğŸ”„ æ­£åœ¨ä»Pascal VOCæ ¼å¼è½¬æ¢...")
        
        # æŸ¥æ‰¾XMLæ ‡æ³¨æ–‡ä»¶
        xml_files = list(input_path.glob("**/*.xml"))
        
        if not xml_files:
            raise ValueError("æœªæ‰¾åˆ°Pascal VOCæ ¼å¼çš„XMLæ ‡æ³¨æ–‡ä»¶")
        
        converted_count = 0
        
        for xml_file in tqdm(xml_files, desc="è½¬æ¢VOCæ ‡æ³¨"):
            try:
                # è§£æXMLæ–‡ä»¶
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                # è·å–å›¾åƒä¿¡æ¯
                filename = root.find('filename').text
                size = root.find('size')
                img_width = int(size.find('width').text)
                img_height = int(size.find('height').text)
                
                # æŸ¥æ‰¾å¯¹åº”çš„å›¾åƒæ–‡ä»¶
                image_path = self._find_image_file(input_path, filename)
                if not image_path:
                    print(f"âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {filename}")
                    continue
                
                # ç¡®å®šåˆ†å‰²ç±»å‹ï¼ˆç®€å•è§„åˆ™ï¼‰
                split = 'train' if converted_count % 5 != 0 else 'val'
                
                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                target_img_path = output_path / "images" / split / filename
                shutil.copy2(image_path, target_img_path)
                
                # è½¬æ¢æ ‡æ³¨
                yolo_annotations = []
                for obj in root.findall('object'):
                    bbox = obj.find('bndbox')
                    xmin = float(bbox.find('xmin').text)
                    ymin = float(bbox.find('ymin').text)
                    xmax = float(bbox.find('xmax').text)
                    ymax = float(bbox.find('ymax').text)
                    
                    # è½¬æ¢ä¸ºYOLOæ ¼å¼
                    x_center = (xmin + xmax) / 2 / img_width
                    y_center = (ymin + ymax) / 2 / img_height
                    width = (xmax - xmin) / img_width
                    height = (ymax - ymin) / img_height
                    
                    # ç±»åˆ«ID (å‡è®¾çƒæ†ç±»åˆ«ä¸º0)
                    class_id = 0
                    
                    yolo_annotations.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
                
                # ä¿å­˜YOLOæ ‡æ³¨æ–‡ä»¶
                if yolo_annotations:
                    label_filename = Path(filename).stem + '.txt'
                    label_path = output_path / "labels" / split / label_filename
                    
                    with open(label_path, 'w') as f:
                        f.write('\n'.join(yolo_annotations) + '\n')
                    
                    converted_count += 1
                    
            except Exception as e:
                print(f"âš ï¸ è½¬æ¢XMLæ–‡ä»¶å¤±è´¥ {xml_file.name}: {str(e)}")
                continue
        
        print(f"âœ… VOCè½¬æ¢å®Œæˆï¼Œå…±è½¬æ¢ {converted_count} ä¸ªæ ·æœ¬")
    
    def _copy_yolo_dataset(self, input_path, output_path):
        """å¤åˆ¶å·²æœ‰çš„YOLOæ ¼å¼æ•°æ®é›†"""
        print("ğŸ”„ æ­£åœ¨å¤åˆ¶YOLOæ ¼å¼æ•°æ®é›†...")
        
        # æŸ¥æ‰¾YOLOæ ¼å¼çš„ç›®å½•ç»“æ„
        if (input_path / "images").exists() and (input_path / "labels").exists():
            # æ ‡å‡†YOLOç»“æ„
            for split in ['train', 'val']:
                img_src = input_path / "images" / split
                label_src = input_path / "labels" / split
                
                if img_src.exists():
                    img_dst = output_path / "images" / split
                    shutil.copytree(img_src, img_dst, dirs_exist_ok=True)
                
                if label_src.exists():
                    label_dst = output_path / "labels" / split
                    shutil.copytree(label_src, label_dst, dirs_exist_ok=True)
        else:
            # æ‰å¹³ç»“æ„ï¼Œéœ€è¦é‡æ–°ç»„ç»‡
            self._reorganize_flat_yolo_dataset(input_path, output_path)
        
        print("âœ… YOLOæ•°æ®é›†å¤åˆ¶å®Œæˆ")
    
    def _reorganize_flat_yolo_dataset(self, input_path, output_path):
        """é‡æ–°ç»„ç»‡æ‰å¹³çš„YOLOæ•°æ®é›†"""
        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒå’Œæ ‡æ³¨æ–‡ä»¶
        image_files = []
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            image_files.extend(list(input_path.glob(f"**/*{ext}")))
            image_files.extend(list(input_path.glob(f"**/*{ext.upper()}")))
        
        label_files = list(input_path.glob("**/*.txt"))
        
        # åˆ›å»ºæ–‡ä»¶ååˆ°è·¯å¾„çš„æ˜ å°„
        label_dict = {f.stem: f for f in label_files}
        
        converted_count = 0
        
        for i, img_file in enumerate(image_files):
            # ç¡®å®šåˆ†å‰²ç±»å‹ (80% è®­ç»ƒ, 20% éªŒè¯)
            split = 'train' if i % 5 != 0 else 'val'
            
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            target_img_path = output_path / "images" / split / img_file.name
            shutil.copy2(img_file, target_img_path)
            
            # æŸ¥æ‰¾å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
            if img_file.stem in label_dict:
                label_file = label_dict[img_file.stem]
                target_label_path = output_path / "labels" / split / f"{img_file.stem}.txt"
                shutil.copy2(label_file, target_label_path)
                converted_count += 1
        
        print(f"âœ… é‡æ–°ç»„ç»‡å®Œæˆï¼Œå…±å¤„ç† {converted_count} ä¸ªæ ·æœ¬")
    
    def _find_image_file(self, base_path, filename):
        """æŸ¥æ‰¾å›¾åƒæ–‡ä»¶"""
        # å°è¯•ä¸åŒçš„å¯èƒ½è·¯å¾„
        possible_paths = [
            base_path / filename,
            base_path / "images" / filename,
            base_path / "train" / filename,
            base_path / "val" / filename,
            base_path / "test" / filename
        ]
        
        # é€’å½’æœç´¢
        for path in base_path.rglob(filename):
            return path
        
        return None
    
    def _generate_yolo_config(self, output_path):
        """ç”ŸæˆYOLOé…ç½®æ–‡ä»¶"""
        config = {
            'path': str(output_path.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'nc': 1,
            'names': ['golf_club']
        }
        
        config_file = output_path / 'dataset.yaml'
        
        # æ‰‹åŠ¨å†™å…¥YAMLæ ¼å¼ï¼ˆé¿å…ä¾èµ–yamlåº“ï¼‰
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(f"# Golf Club Detection Dataset Configuration\n")
            f.write(f"path: {config['path']}\n")
            f.write(f"train: {config['train']}\n")
            f.write(f"val: {config['val']}\n")
            f.write(f"nc: {config['nc']}\n")
            f.write(f"names: {config['names']}\n")
        
        print(f"ğŸ“ YOLOé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_file}")
    
    def validate_yolo_dataset(self, dataset_path):
        """éªŒè¯YOLOæ•°æ®é›†çš„å®Œæ•´æ€§"""
        dataset_path = Path(dataset_path)
        
        print("ğŸ” éªŒè¯YOLOæ•°æ®é›†...")
        
        issues = []
        
        # æ£€æŸ¥ç›®å½•ç»“æ„
        required_dirs = [
            "images/train", "images/val",
            "labels/train", "labels/val"
        ]
        
        for dir_name in required_dirs:
            dir_path = dataset_path / dir_name
            if not dir_path.exists():
                issues.append(f"ç¼ºå°‘ç›®å½•: {dir_name}")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_file = dataset_path / "dataset.yaml"
        if not config_file.exists():
            issues.append("ç¼ºå°‘é…ç½®æ–‡ä»¶: dataset.yaml")
        
        # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        for split in ['train', 'val']:
            img_dir = dataset_path / "images" / split
            label_dir = dataset_path / "labels" / split
            
            if img_dir.exists() and label_dir.exists():
                img_files = set(f.stem for f in img_dir.glob("*") if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp'])
                label_files = set(f.stem for f in label_dir.glob("*.txt"))
                
                missing_labels = img_files - label_files
                missing_images = label_files - img_files
                
                if missing_labels:
                    issues.append(f"{split}é›†ä¸­ {len(missing_labels)} ä¸ªå›¾åƒç¼ºå°‘æ ‡æ³¨æ–‡ä»¶")
                
                if missing_images:
                    issues.append(f"{split}é›†ä¸­ {len(missing_images)} ä¸ªæ ‡æ³¨æ–‡ä»¶ç¼ºå°‘å¯¹åº”å›¾åƒ")
        
        # è¾“å‡ºéªŒè¯ç»“æœ
        if issues:
            print("âŒ æ•°æ®é›†éªŒè¯å‘ç°é—®é¢˜:")
            for issue in issues:
                print(f"  - {issue}")
        else:
            print("âœ… æ•°æ®é›†éªŒè¯é€šè¿‡")
        
        return len(issues) == 0

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ•°æ®é›†æ ¼å¼è½¬æ¢å·¥å…·")
    parser.add_argument("input_dir", help="è¾“å…¥æ•°æ®é›†ç›®å½•")
    parser.add_argument("output_dir", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--input_format", "-i", choices=['coco', 'voc', 'yolo'], 
                       required=True, help="è¾“å…¥æ•°æ®æ ¼å¼")
    parser.add_argument("--output_format", "-o", choices=['yolo'], 
                       default='yolo', help="è¾“å‡ºæ•°æ®æ ¼å¼")
    parser.add_argument("--validate", action="store_true", help="è½¬æ¢åéªŒè¯æ•°æ®é›†")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºè½¬æ¢å™¨
        converter = DatasetConverter()
        
        # æ‰§è¡Œè½¬æ¢
        converter.convert_dataset(
            input_dir=args.input_dir,
            output_dir=args.output_dir,
            input_format=args.input_format,
            output_format=args.output_format
        )
        
        # éªŒè¯æ•°æ®é›†
        if args.validate:
            converter.validate_yolo_dataset(args.output_dir)
        
    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 