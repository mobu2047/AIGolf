#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOé«˜å°”å¤«çƒæ†æ£€æµ‹è‡ªåŠ¨åŒ–è®­ç»ƒç³»ç»Ÿ
ç”¨æˆ·åªéœ€æ”¾å…¥æ•°æ®å³å¯è‡ªåŠ¨å®Œæˆè®­ç»ƒçš„å®Œæ•´æµç¨‹
"""

import os
import json
import yaml
import shutil
import hashlib
import traceback
from datetime import datetime
from pathlib import Path
import cv2
import numpy as np
from ultralytics import YOLO
import torch

class AutoTrainingSystem:
    """è‡ªåŠ¨åŒ–è®­ç»ƒç³»ç»Ÿæ ¸å¿ƒç±»"""
    
    def __init__(self, base_dir="yolo_dataset_full"):
        """
        åˆå§‹åŒ–è‡ªåŠ¨åŒ–è®­ç»ƒç³»ç»Ÿ
        
        Args:
            base_dir: åŸºç¡€ç›®å½•è·¯å¾„
        """
        self.base_dir = Path(base_dir)
        # è®­ç»ƒç³»ç»Ÿçš„è¾“å…¥è·¯å¾„ä¸ºè§†é¢‘æ ‡æ³¨ç³»ç»Ÿçš„è¾“å‡ºè·¯å¾„
        self.input_dir = Path(r"C:\Users\Administrator\Desktop\AIGolf\dataset")
        self.processed_dir = self.base_dir / "processed"
        self.archive_dir = self.base_dir / "archive"
        self.models_dir = self.base_dir / "models"
        self.configs_dir = self.base_dir / "configs"
        self.logs_dir = self.base_dir / "logs"
        self.temp_dir = self.base_dir / "temp"
        # å·²è®­ç»ƒæ•°æ®å­˜å‚¨ç›®å½•
        self.trained_data_dir = self.base_dir / "trained_data"
        
        # ç¡®ä¿æ‰€æœ‰ç›®å½•å­˜åœ¨
        self._ensure_directories()
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.processing_log = []
        
        print(f"ğŸš€ è‡ªåŠ¨åŒ–è®­ç»ƒç³»ç»Ÿå·²åˆå§‹åŒ–")
        print(f"ğŸ“ åŸºç¡€ç›®å½•: {self.base_dir.absolute()}")
        print(f"ğŸ“ è®­ç»ƒè¾“å…¥ç›®å½•: {self.input_dir.absolute()} (è§†é¢‘æ ‡æ³¨è¾“å‡º)")
        print(f"ğŸ“ å·²è®­ç»ƒæ•°æ®ç›®å½•: {self.trained_data_dir.absolute()}")
    
    def _ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦ç›®å½•å­˜åœ¨"""
        directories = [
            # ä¸å†åˆ›å»ºinputç›®å½•ï¼Œå› ä¸ºä½¿ç”¨å›ºå®šè·¯å¾„
            self.processed_dir / "images" / "train",
            self.processed_dir / "images" / "val",
            self.processed_dir / "labels" / "train",
            self.processed_dir / "labels" / "val",
            self.archive_dir,
            self.models_dir / "latest",
            self.configs_dir,
            self.logs_dir,
            self.temp_dir,
            # å·²è®­ç»ƒæ•°æ®ç›®å½•
            self.trained_data_dir / "images",
            self.trained_data_dir / "annotations",
            self.trained_data_dir / "metadata"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        # ç¡®ä¿å›ºå®šè¾“å…¥ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not self.input_dir.exists():
            print(f"ğŸ“ åˆ›å»ºè®­ç»ƒè¾“å…¥ç›®å½•: {self.input_dir}")
            self.input_dir.mkdir(parents=True, exist_ok=True)
    
    def run(self):
        """
        ä¸»è¿è¡Œå‡½æ•° - ç”¨æˆ·åªéœ€è°ƒç”¨è¿™ä¸€ä¸ªå‡½æ•°
        è‡ªåŠ¨æ£€æµ‹æ–°æ•°æ®å¹¶å®Œæˆè®­ç»ƒæµç¨‹
        """
        print("\n" + "="*60)
        print("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–è®­ç»ƒç³»ç»Ÿ...")
        print("="*60)
        
        try:
            # 1. æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦æœ‰æ–°æ•°æ®
            new_data_found = self._check_for_new_data()
            
            if new_data_found:
                print("ğŸ“ å‘ç°æ–°æ•°æ®ï¼Œå¼€å§‹è‡ªåŠ¨å¤„ç†...")
                
                # 2. å¤„ç†æ–°æ•°æ®
                batch_id = self._process_new_data()
                
                # 3. è‡ªåŠ¨è®­ç»ƒ
                self._auto_train(batch_id)
                
                # 4. æ¸…ç†è¾“å…¥ç›®å½•
                self._cleanup_input_directory()
                
                print("âœ… è®­ç»ƒå®Œæˆï¼æ–°æ•°æ®å·²è‡ªåŠ¨æ•´åˆåˆ°è®­ç»ƒé›†ä¸­")
            else:
                print("ğŸ“‚ è¾“å…¥ç›®å½•ä¸­æœªå‘ç°æ–°æ•°æ®")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰æ•°æ®å¯ä»¥è®­ç»ƒ
                if self._has_existing_data():
                    print("ğŸ”„ ä½¿ç”¨ç°æœ‰æ•°æ®è¿›è¡Œè®­ç»ƒ...")
                    self._auto_train()
                else:
                    print("âŒ æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®")
                    self._create_input_directory_guide()
                    
        except Exception as e:
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            self._handle_error(e)
    
    def _check_for_new_data(self):
        """æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦æœ‰æ–°æ•°æ®"""
        if not self.input_dir.exists():
            print(f"âš ï¸ è®­ç»ƒè¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.input_dir}")
            return False
        
        # ç›´æ¥åœ¨datasetç›®å½•ä¸­æ£€æŸ¥å›¾åƒæ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        images = []
        for ext in image_extensions:
            images.extend(list(self.input_dir.glob(f"*{ext}")))
            images.extend(list(self.input_dir.glob(f"*{ext.upper()}")))
        
        # ä¹Ÿæ£€æŸ¥imageså­ç›®å½•ï¼ˆè§†é¢‘æ ‡æ³¨ç³»ç»Ÿçš„è¾“å‡ºç»“æ„ï¼‰
        images_subdir = self.input_dir / "images"
        if images_subdir.exists():
            for ext in image_extensions:
                images.extend(list(images_subdir.glob(f"*{ext}")))
                images.extend(list(images_subdir.glob(f"*{ext.upper()}")))
        
        # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        annotation_extensions = ['.txt', '.json', '.xml']
        annotations = []
        
        # åœ¨datasetç›®å½•ä¸­æŸ¥æ‰¾æ ‡æ³¨æ–‡ä»¶
        for ext in annotation_extensions:
            annotations.extend(list(self.input_dir.glob(f"*{ext}")))
        
        # ä¹Ÿæ£€æŸ¥annotationså­ç›®å½•ï¼ˆè§†é¢‘æ ‡æ³¨ç³»ç»Ÿçš„è¾“å‡ºç»“æ„ï¼‰
        annotations_subdir = self.input_dir / "annotations"
        if annotations_subdir.exists():
            for ext in annotation_extensions:
                annotations.extend(list(annotations_subdir.glob(f"*{ext}")))
        
        print(f"ğŸ“Š å‘ç° {len(images)} ä¸ªå›¾åƒæ–‡ä»¶")
        print(f"ğŸ“Š å‘ç° {len(annotations)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        return len(images) > 0
    
    def _process_new_data(self):
        """è‡ªåŠ¨å¤„ç†æ–°æ•°æ®"""
        # ç”Ÿæˆæ‰¹æ¬¡ID
        batch_id = self._generate_batch_id()
        print(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡: {batch_id}")
        
        try:
            # 1. éªŒè¯æ–°æ•°æ®
            self._log_step("éªŒè¯è¾“å…¥æ•°æ®")
            self._validate_input_data()
            
            # 2. è½¬æ¢æ•°æ®æ ¼å¼
            self._log_step("è½¬æ¢æ•°æ®æ ¼å¼")
            converted_data = self._convert_data_format()
            
            # 3. å»é‡æ£€æŸ¥
            self._log_step("æ£€æŸ¥é‡å¤æ•°æ®")
            unique_data = self._remove_duplicates(converted_data)
            
            # 4. åˆå¹¶åˆ°ç°æœ‰æ•°æ®é›†
            self._log_step("åˆå¹¶åˆ°è®­ç»ƒæ•°æ®é›†")
            self._merge_to_processed_dataset(unique_data)
            
            # 5. å¤‡ä»½æ–°æ•°æ®åˆ°archive
            self._log_step("å¤‡ä»½æ•°æ®åˆ°å½’æ¡£ç›®å½•")
            self._archive_batch(batch_id, unique_data)
            
            # 6. é‡æ–°åˆ†å‰²æ•°æ®é›†
            self._log_step("é‡æ–°åˆ†å‰²è®­ç»ƒ/éªŒè¯é›†")
            self._resplit_dataset()
            
            # 7. æ›´æ–°é…ç½®æ–‡ä»¶
            self._log_step("æ›´æ–°é…ç½®æ–‡ä»¶")
            self._update_configs()
            
            print(f"âœ… æ‰¹æ¬¡ {batch_id} å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(unique_data)} ä¸ªæ ·æœ¬")
            return batch_id
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ‰¹æ¬¡ {batch_id} æ—¶å‡ºé”™: {str(e)}")
            raise
    
    def _generate_batch_id(self):
        """ç”Ÿæˆæ‰¹æ¬¡ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{timestamp}"
    
    def _validate_input_data(self):
        """éªŒè¯è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§"""
        if not self.input_dir.exists():
            raise ValueError(f"è®­ç»ƒè¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.input_dir}")
        
        # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å¯è¯»
        valid_images = 0
        for img_path in self.input_dir.iterdir():
            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                try:
                    img = cv2.imread(str(img_path))
                    if img is not None:
                        valid_images += 1
                    else:
                        print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {img_path.name}")
                except Exception as e:
                    print(f"âš ï¸ å›¾åƒæ–‡ä»¶æŸå: {img_path.name} - {str(e)}")
        
        if valid_images == 0:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶")
        
        print(f"âœ… éªŒè¯é€šè¿‡ï¼Œå‘ç° {valid_images} ä¸ªæœ‰æ•ˆå›¾åƒ")
    
    def _convert_data_format(self):
        """è‡ªåŠ¨æ£€æµ‹å¹¶è½¬æ¢æ•°æ®æ ¼å¼ä¸ºYOLOæ ¼å¼"""
        converted_data = []
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒè§†é¢‘æ ‡æ³¨ç³»ç»Ÿçš„è¾“å‡ºç»“æ„ï¼‰
        image_files = []
        
        # ç›´æ¥åœ¨datasetç›®å½•ä¸­æŸ¥æ‰¾
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            image_files.extend(list(self.input_dir.glob(f"*{ext}")))
            image_files.extend(list(self.input_dir.glob(f"*{ext.upper()}")))
        
        # ä¹Ÿåœ¨imageså­ç›®å½•ä¸­æŸ¥æ‰¾ï¼ˆè§†é¢‘æ ‡æ³¨ç³»ç»Ÿçš„è¾“å‡ºç»“æ„ï¼‰
        images_subdir = self.input_dir / "images"
        if images_subdir.exists():
            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                image_files.extend(list(images_subdir.glob(f"*{ext}")))
                image_files.extend(list(images_subdir.glob(f"*{ext.upper()}")))
        
        print(f"ğŸ”„ å¼€å§‹è½¬æ¢ {len(image_files)} ä¸ªå›¾åƒçš„æ ‡æ³¨...")
        
        for img_path in image_files:
            # æŸ¥æ‰¾å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
            annotation_path = self._find_annotation_file(img_path)
            
            if annotation_path:
                try:
                    # æ ¹æ®æ–‡ä»¶æ‰©å±•åè½¬æ¢æ ¼å¼
                    if annotation_path.suffix.lower() == '.json':
                        # COCOæ ¼å¼è½¬æ¢
                        yolo_annotation = self._convert_coco_to_yolo(img_path, annotation_path)
                    elif annotation_path.suffix.lower() == '.txt':
                        # å·²ç»æ˜¯YOLOæ ¼å¼ï¼Œç›´æ¥å¤åˆ¶
                        yolo_annotation = annotation_path
                    elif annotation_path.suffix.lower() == '.xml':
                        # Pascal VOCæ ¼å¼è½¬æ¢
                        yolo_annotation = self._convert_voc_to_yolo(img_path, annotation_path)
                    else:
                        print(f"âš ï¸ ä¸æ”¯æŒçš„æ ‡æ³¨æ ¼å¼: {annotation_path}")
                        continue
                    
                    converted_data.append({
                        'image': img_path,
                        'annotation': yolo_annotation,
                        'image_id': img_path.stem,
                        'source_annotation': annotation_path
                    })
                    
                except Exception as e:
                    print(f"âš ï¸ è½¬æ¢æ ‡æ³¨å¤±è´¥ {annotation_path.name}: {str(e)}")
                    continue
            else:
                # æ²¡æœ‰æ ‡æ³¨æ–‡ä»¶ï¼Œéœ€è¦äº¤äº’å¼æ ‡æ³¨
                print(f"âš ï¸ å›¾åƒ {img_path.name} æ²¡æœ‰å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶ï¼Œå°†è·³è¿‡")
                # å¯ä»¥åœ¨è¿™é‡Œè°ƒç”¨äº¤äº’å¼æ ‡æ³¨
                continue
        
        print(f"âœ… æˆåŠŸè½¬æ¢ {len(converted_data)} ä¸ªæ ·æœ¬")
        return converted_data
    
    def _find_annotation_file(self, img_path):
        """æŸ¥æ‰¾å›¾åƒå¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶"""
        base_name = img_path.stem
        
        # å°è¯•ä¸åŒçš„æ ‡æ³¨æ–‡ä»¶æ‰©å±•åå’Œä½ç½®
        search_locations = [
            self.input_dir,  # ç›´æ¥åœ¨datasetç›®å½•ä¸­
            self.input_dir / "annotations",  # åœ¨annotationså­ç›®å½•ä¸­ï¼ˆè§†é¢‘æ ‡æ³¨ç³»ç»Ÿè¾“å‡ºï¼‰
            img_path.parent  # åœ¨å›¾åƒæ–‡ä»¶åŒç›®å½•ä¸­
        ]
        
        for location in search_locations:
            if not location.exists():
                continue
                
            for ext in ['.txt', '.json', '.xml']:
                annotation_path = location / f"{base_name}{ext}"
                if annotation_path.exists():
                    return annotation_path
        
        return None
    
    def _convert_coco_to_yolo(self, img_path, coco_path):
        """å°†COCOæ ¼å¼è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        # è¯»å–å›¾åƒå°ºå¯¸
        img = cv2.imread(str(img_path))
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")
        
        img_height, img_width = img.shape[:2]
        
        # è¯»å–COCOæ ‡æ³¨
        with open(coco_path, 'r', encoding='utf-8') as f:
            coco_data = json.load(f)
        
        # åˆ›å»ºYOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶
        yolo_path = self.temp_dir / f"{img_path.stem}.txt"
        
        with open(yolo_path, 'w') as f:
            # å¤„ç†COCOæ ‡æ³¨ä¸­çš„æ¯ä¸ªå¯¹è±¡
            if 'annotations' in coco_data:
                for annotation in coco_data['annotations']:
                    if 'bbox' in annotation:
                        # COCO bboxæ ¼å¼: [x, y, width, height]
                        x, y, w, h = annotation['bbox']
                        
                        # è½¬æ¢ä¸ºYOLOæ ¼å¼ (å½’ä¸€åŒ–çš„ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜)
                        x_center = (x + w / 2) / img_width
                        y_center = (y + h / 2) / img_height
                        norm_width = w / img_width
                        norm_height = h / img_height
                        
                        # ç±»åˆ«ID (å‡è®¾çƒæ†ç±»åˆ«ä¸º0)
                        class_id = 0
                        
                        f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\n")
        
        return yolo_path
    
    def _convert_voc_to_yolo(self, img_path, voc_path):
        """å°†Pascal VOCæ ¼å¼è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        import xml.etree.ElementTree as ET
        
        # è¯»å–å›¾åƒå°ºå¯¸
        img = cv2.imread(str(img_path))
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")
        
        img_height, img_width = img.shape[:2]
        
        # è§£æXMLæ–‡ä»¶
        tree = ET.parse(voc_path)
        root = tree.getroot()
        
        # åˆ›å»ºYOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶
        yolo_path = self.temp_dir / f"{img_path.stem}.txt"
        
        with open(yolo_path, 'w') as f:
            for obj in root.findall('object'):
                # è·å–è¾¹ç•Œæ¡†åæ ‡
                bbox = obj.find('bndbox')
                xmin = float(bbox.find('xmin').text)
                ymin = float(bbox.find('ymin').text)
                xmax = float(bbox.find('xmax').text)
                ymax = float(bbox.find('ymax').text)
                
                # è½¬æ¢ä¸ºYOLOæ ¼å¼
                x_center = (xmin + xmax) / 2 / img_width
                y_center = (ymin + ymax) / 2 / img_height
                width = (xmax - xmin) / img_width
                height = (ymax - ymin) / img_height
                
                # ç±»åˆ«ID (å‡è®¾çƒæ†ç±»åˆ«ä¸º0)
                class_id = 0
                
                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
        
        return yolo_path
    
    def _remove_duplicates(self, data_list):
        """å»é™¤é‡å¤çš„å›¾åƒæ•°æ®"""
        print("ğŸ” æ£€æŸ¥é‡å¤æ•°æ®...")
        
        unique_data = []
        seen_hashes = set()
        
        for item in data_list:
            # è®¡ç®—å›¾åƒæ–‡ä»¶çš„å“ˆå¸Œå€¼
            img_hash = self._calculate_file_hash(item['image'])
            
            if img_hash not in seen_hashes:
                seen_hashes.add(img_hash)
                unique_data.append(item)
            else:
                print(f"âš ï¸ å‘ç°é‡å¤å›¾åƒ: {item['image'].name}")
        
        removed_count = len(data_list) - len(unique_data)
        if removed_count > 0:
            print(f"ğŸ—‘ï¸ ç§»é™¤äº† {removed_count} ä¸ªé‡å¤æ ·æœ¬")
        else:
            print("âœ… æœªå‘ç°é‡å¤æ•°æ®")
        
        return unique_data
    
    def _calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _merge_to_processed_dataset(self, unique_data):
        """å°†æ–°æ•°æ®åˆå¹¶åˆ°å·²å¤„ç†çš„æ•°æ®é›†ä¸­"""
        print(f"ğŸ“¥ åˆå¹¶ {len(unique_data)} ä¸ªæ ·æœ¬åˆ°è®­ç»ƒæ•°æ®é›†...")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾æ–°æ•°æ®
        temp_images_dir = self.temp_dir / "new_images"
        temp_labels_dir = self.temp_dir / "new_labels"
        temp_images_dir.mkdir(exist_ok=True)
        temp_labels_dir.mkdir(exist_ok=True)
        
        merged_count = 0
        
        for item in unique_data:
            try:
                # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆé¿å…ä¸ç°æœ‰æ–‡ä»¶å†²çªï¼‰
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                new_name = f"{item['image_id']}_{timestamp}"
                
                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                new_img_path = temp_images_dir / f"{new_name}{item['image'].suffix}"
                shutil.copy2(item['image'], new_img_path)
                
                # å¤åˆ¶æ ‡æ³¨æ–‡ä»¶
                new_label_path = temp_labels_dir / f"{new_name}.txt"
                shutil.copy2(item['annotation'], new_label_path)
                
                merged_count += 1
                
            except Exception as e:
                print(f"âš ï¸ åˆå¹¶æ ·æœ¬å¤±è´¥ {item['image'].name}: {str(e)}")
                continue
        
        print(f"âœ… æˆåŠŸåˆå¹¶ {merged_count} ä¸ªæ ·æœ¬")
        return merged_count
    
    def _resplit_dataset(self):
        """é‡æ–°åˆ†å‰²æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
        print("ğŸ”„ é‡æ–°åˆ†å‰²æ•°æ®é›†...")
        
        # æ”¶é›†æ‰€æœ‰æ•°æ®ï¼ˆç°æœ‰çš„ + æ–°çš„ï¼‰
        all_images = []
        
        # ç°æœ‰çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†
        for split in ['train', 'val']:
            images_dir = self.processed_dir / "images" / split
            if images_dir.exists():
                all_images.extend(list(images_dir.glob("*")))
        
        # æ–°æ·»åŠ çš„æ•°æ®
        temp_images_dir = self.temp_dir / "new_images"
        if temp_images_dir.exists():
            all_images.extend(list(temp_images_dir.glob("*")))
        
        # æ¸…ç©ºç°æœ‰çš„åˆ†å‰²
        for split in ['train', 'val']:
            images_dir = self.processed_dir / "images" / split
            labels_dir = self.processed_dir / "labels" / split
            
            if images_dir.exists():
                shutil.rmtree(images_dir)
            if labels_dir.exists():
                shutil.rmtree(labels_dir)
            
            images_dir.mkdir(parents=True, exist_ok=True)
            labels_dir.mkdir(parents=True, exist_ok=True)
        
        # éšæœºåˆ†å‰² (80% è®­ç»ƒ, 20% éªŒè¯)
        import random
        random.shuffle(all_images)
        
        split_point = int(len(all_images) * 0.8)
        train_images = all_images[:split_point]
        val_images = all_images[split_point:]
        
        # ç§»åŠ¨æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
        self._move_split_files(train_images, 'train')
        self._move_split_files(val_images, 'val')
        
        print(f"âœ… æ•°æ®é›†é‡æ–°åˆ†å‰²å®Œæˆ:")
        print(f"   è®­ç»ƒé›†: {len(train_images)} ä¸ªæ ·æœ¬")
        print(f"   éªŒè¯é›†: {len(val_images)} ä¸ªæ ·æœ¬")
    
    def _move_split_files(self, image_list, split_name):
        """ç§»åŠ¨æ–‡ä»¶åˆ°æŒ‡å®šçš„åˆ†å‰²ç›®å½•"""
        images_dir = self.processed_dir / "images" / split_name
        labels_dir = self.processed_dir / "labels" / split_name
        
        for img_path in image_list:
            # ç§»åŠ¨å›¾åƒæ–‡ä»¶
            new_img_path = images_dir / img_path.name
            if img_path.parent != images_dir:
                shutil.move(str(img_path), str(new_img_path))
            
            # æŸ¥æ‰¾å¹¶ç§»åŠ¨å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
            label_name = img_path.stem + ".txt"
            
            # åœ¨å¤šä¸ªå¯èƒ½çš„ä½ç½®æŸ¥æ‰¾æ ‡æ³¨æ–‡ä»¶
            possible_label_paths = [
                img_path.parent.parent / "labels" / split_name / label_name,  # ç°æœ‰ç»“æ„
                self.temp_dir / "new_labels" / label_name,  # æ–°æ•°æ®
                img_path.with_suffix('.txt')  # åŒç›®å½•
            ]
            
            for label_path in possible_label_paths:
                if label_path.exists():
                    new_label_path = labels_dir / label_name
                    if label_path != new_label_path:
                        shutil.move(str(label_path), str(new_label_path))
                    break
    
    def _update_configs(self):
        """æ›´æ–°æ‰€æœ‰é…ç½®æ–‡ä»¶"""
        print("ğŸ“ æ›´æ–°é…ç½®æ–‡ä»¶...")
        
        # æ›´æ–°YOLOæ•°æ®é›†é…ç½®
        dataset_config = {
            'path': str(self.processed_dir.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'nc': 1,
            'names': ['golf_club']
        }
        
        config_file = self.configs_dir / 'dataset.yaml'
        with open(config_file, 'w', encoding='utf-8') as f:
            yaml.dump(dataset_config, f, default_flow_style=False, allow_unicode=True)
        
        # æ›´æ–°è®­ç»ƒé…ç½®
        training_config = {
            'last_update': datetime.now().isoformat(),
            'dataset_path': str(self.processed_dir.absolute()),
            'model_save_path': str(self.models_dir.absolute()),
            'total_samples': self._count_total_samples()
        }
        
        with open(self.configs_dir / 'training_config.json', 'w', encoding='utf-8') as f:
            json.dump(training_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°: {config_file}")
    
    def _count_total_samples(self):
        """ç»Ÿè®¡æ€»æ ·æœ¬æ•°"""
        train_count = len(list((self.processed_dir / "images" / "train").glob("*")))
        val_count = len(list((self.processed_dir / "images" / "val").glob("*")))
        return train_count + val_count
    
    def _archive_batch(self, batch_id, data):
        """å½’æ¡£æ‰¹æ¬¡æ•°æ®"""
        batch_dir = self.archive_dir / f"batch_{batch_id}"
        batch_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ‰¹æ¬¡ä¿¡æ¯
        batch_info = {
            'batch_id': batch_id,
            'timestamp': datetime.now().isoformat(),
            'sample_count': len(data),
            'source': 'input_directory',
            'processing_log': self.processing_log.copy(),
            'samples': [
                {
                    'image_name': item['image'].name,
                    'image_id': item['image_id'],
                    'annotation_source': str(item.get('source_annotation', 'unknown'))
                }
                for item in data
            ]
        }
        
        with open(batch_dir / 'batch_info.json', 'w', encoding='utf-8') as f:
            json.dump(batch_info, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“¦ æ‰¹æ¬¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {batch_dir}")
    
    def _auto_train(self, batch_id=None):
        """è‡ªåŠ¨å†³å®šè®­ç»ƒç­–ç•¥å¹¶æ‰§è¡Œè®­ç»ƒ"""
        print("\n" + "="*50)
        print("ğŸ¯ å¼€å§‹è‡ªåŠ¨è®­ç»ƒ...")
        print("="*50)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²è®­ç»ƒæ¨¡å‹
        latest_model = self._find_latest_model()
        
        # è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        dataset_stats = self._get_dataset_stats()
        
        # æ™ºèƒ½å†³å®šè®­ç»ƒå‚æ•°
        training_config = self._determine_training_config(latest_model, dataset_stats, batch_id)
        
        print(f"ğŸ¯ è®­ç»ƒæ¨¡å¼: {training_config['mode']}")
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡: {dataset_stats['total_images']} å›¾åƒ, {dataset_stats['total_annotations']} æ ‡æ³¨")
        print(f"âš™ï¸ è®­ç»ƒå‚æ•°: {training_config['epochs']} è½®, å­¦ä¹ ç‡ {training_config['lr0']}")
        
        # æ‰§è¡Œè®­ç»ƒ
        results = self._execute_training(training_config)
        
        # è®­ç»ƒåå¤„ç†
        self._post_training_process(results, training_config)
    
    def _find_latest_model(self):
        """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ¨¡å‹"""
        latest_dir = self.models_dir / "latest"
        best_model = latest_dir / "best.pt"
        
        if best_model.exists():
            print(f"ğŸ” æ‰¾åˆ°å·²æœ‰æ¨¡å‹: {best_model}")
            return str(best_model)
        
        print("ğŸ” æœªæ‰¾åˆ°å·²æœ‰æ¨¡å‹ï¼Œå°†è¿›è¡Œå…¨æ–°è®­ç»ƒ")
        return None
    
    def _get_dataset_stats(self):
        """è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        train_images = list((self.processed_dir / "images" / "train").glob("*"))
        val_images = list((self.processed_dir / "images" / "val").glob("*"))
        
        train_labels = list((self.processed_dir / "labels" / "train").glob("*.txt"))
        val_labels = list((self.processed_dir / "labels" / "val").glob("*.txt"))
        
        # ç»Ÿè®¡æ ‡æ³¨æ•°é‡
        total_annotations = 0
        for label_file in train_labels + val_labels:
            try:
                with open(label_file, 'r') as f:
                    total_annotations += len(f.readlines())
            except:
                continue
        
        return {
            'total_images': len(train_images) + len(val_images),
            'train_images': len(train_images),
            'val_images': len(val_images),
            'total_annotations': total_annotations
        }
    
    def _determine_training_config(self, latest_model, dataset_stats, batch_id):
        """æ™ºèƒ½ç¡®å®šè®­ç»ƒé…ç½®"""
        config = {
            'mode': 'fresh',
            'epochs': 100,
            'lr0': 0.01,
            'batch_size': 16,
            'patience': 50,
            'device': 0 if torch.cuda.is_available() else 'cpu'
        }
        
        if latest_model:
            # æœ‰å·²è®­ç»ƒæ¨¡å‹ï¼Œè¿›è¡Œå¢é‡è®­ç»ƒ
            config.update({
                'mode': 'incremental',
                'base_model': latest_model,
                'epochs': 50,  # è¾ƒå°‘è½®æ•°
                'lr0': 0.001,  # è¾ƒä½å­¦ä¹ ç‡
                'patience': 20
            })
            
            # æ ¹æ®æ–°æ•°æ®é‡è°ƒæ•´å‚æ•°
            if batch_id:
                # è¿™é‡Œå¯ä»¥æ ¹æ®æ–°æ•°æ®æ¯”ä¾‹è°ƒæ•´å‚æ•°
                config['epochs'] = 80
                config['lr0'] = 0.005
        
        # æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´æ‰¹æ¬¡å¤§å°
        if dataset_stats['total_images'] < 100:
            config['batch_size'] = 8
        elif dataset_stats['total_images'] > 1000:
            config['batch_size'] = 32
        
        return config
    
    def _execute_training(self, config):
        """æ‰§è¡ŒYOLOè®­ç»ƒ"""
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œè®­ç»ƒ...")
        
        try:
            # åŠ è½½æ¨¡å‹
            if config['mode'] == 'incremental' and config.get('base_model'):
                print(f"ğŸ“¥ åŠ è½½å·²æœ‰æ¨¡å‹: {config['base_model']}")
                model = YOLO(config['base_model'])
            else:
                print("ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: yolov8n.pt")
                model = YOLO('yolov8n.pt')
            
            # è®­ç»ƒå‚æ•°
            train_args = {
                'data': str(self.configs_dir / 'dataset.yaml'),
                'epochs': config['epochs'],
                'lr0': config['lr0'],
                'batch': config['batch_size'],
                'patience': config['patience'],
                'device': config['device'],
                'project': str(self.models_dir),
                'name': 'latest',
                'exist_ok': True,
                'save': True,
                'verbose': True,
                'imgsz': 640
            }
            
            print(f"âš™ï¸ è®­ç»ƒå‚æ•°: {train_args}")
            
            # å¼€å§‹è®­ç»ƒ
            results = model.train(**train_args)
            
            print("âœ… è®­ç»ƒå®Œæˆ!")
            return results
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            raise
    
    def _post_training_process(self, results, config):
        """è®­ç»ƒåå¤„ç†"""
        print("ğŸ”„ æ‰§è¡Œè®­ç»ƒåå¤„ç†...")
        
        # ä¿å­˜è®­ç»ƒæ—¥å¿—
        training_log = {
            'timestamp': datetime.now().isoformat(),
            'mode': config['mode'],
            'config': config,
            'results_summary': {
                'save_dir': str(results.save_dir) if hasattr(results, 'save_dir') else 'unknown'
            }
        }
        
        log_file = self.logs_dir / f"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(training_log, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜: {log_file}")
        
        # å°†å·²è®­ç»ƒçš„æ•°æ®ç§»åŠ¨åˆ°trained_dataç›®å½•
        self._move_trained_data_to_archive()
        
        print("âœ… è®­ç»ƒåå¤„ç†å®Œæˆ!")
    
    def _move_trained_data_to_archive(self):
        """å°†å·²è®­ç»ƒçš„æ•°æ®ç§»åŠ¨åˆ°trained_dataç›®å½•"""
        print("ğŸ“¦ å½’æ¡£å·²è®­ç»ƒçš„æ•°æ®...")
        
        # ç”Ÿæˆå½’æ¡£æ‰¹æ¬¡ID
        archive_batch_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_batch_dir = self.trained_data_dir / f"batch_{archive_batch_id}"
        
        # åˆ›å»ºå½’æ¡£æ‰¹æ¬¡ç›®å½•
        archive_images_dir = archive_batch_dir / "images"
        archive_annotations_dir = archive_batch_dir / "annotations"
        archive_metadata_dir = archive_batch_dir / "metadata"
        
        archive_images_dir.mkdir(parents=True, exist_ok=True)
        archive_annotations_dir.mkdir(parents=True, exist_ok=True)
        archive_metadata_dir.mkdir(parents=True, exist_ok=True)
        
        moved_count = 0
        
        # ç§»åŠ¨è¾“å…¥ç›®å½•ä¸­çš„æ•°æ®
        if self.input_dir.exists():
            # ç§»åŠ¨å›¾åƒæ–‡ä»¶
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
            
            # ç›´æ¥åœ¨datasetç›®å½•ä¸­çš„å›¾åƒ
            for ext in image_extensions:
                for img_file in self.input_dir.glob(f"*{ext}"):
                    target_file = archive_images_dir / img_file.name
                    shutil.move(str(img_file), str(target_file))
                    moved_count += 1
                for img_file in self.input_dir.glob(f"*{ext.upper()}"):
                    target_file = archive_images_dir / img_file.name
                    shutil.move(str(img_file), str(target_file))
                    moved_count += 1
            
            # imageså­ç›®å½•ä¸­çš„å›¾åƒ
            images_subdir = self.input_dir / "images"
            if images_subdir.exists():
                for ext in image_extensions:
                    for img_file in images_subdir.glob(f"*{ext}"):
                        target_file = archive_images_dir / img_file.name
                        shutil.move(str(img_file), str(target_file))
                        moved_count += 1
                    for img_file in images_subdir.glob(f"*{ext.upper()}"):
                        target_file = archive_images_dir / img_file.name
                        shutil.move(str(img_file), str(target_file))
                        moved_count += 1
                
                # å¦‚æœimagesç›®å½•ä¸ºç©ºï¼Œåˆ é™¤å®ƒ
                if not any(images_subdir.iterdir()):
                    images_subdir.rmdir()
            
            # ç§»åŠ¨æ ‡æ³¨æ–‡ä»¶
            annotation_extensions = ['.txt', '.json', '.xml']
            
            # ç›´æ¥åœ¨datasetç›®å½•ä¸­çš„æ ‡æ³¨
            for ext in annotation_extensions:
                for ann_file in self.input_dir.glob(f"*{ext}"):
                    target_file = archive_annotations_dir / ann_file.name
                    shutil.move(str(ann_file), str(target_file))
            
            # annotationså­ç›®å½•ä¸­çš„æ ‡æ³¨
            annotations_subdir = self.input_dir / "annotations"
            if annotations_subdir.exists():
                for ext in annotation_extensions:
                    for ann_file in annotations_subdir.glob(f"*{ext}"):
                        target_file = archive_annotations_dir / ann_file.name
                        shutil.move(str(ann_file), str(target_file))
                
                # å¦‚æœannotationsç›®å½•ä¸ºç©ºï¼Œåˆ é™¤å®ƒ
                if not any(annotations_subdir.iterdir()):
                    annotations_subdir.rmdir()
            
            # ç§»åŠ¨processed_videosç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            processed_videos_dir = self.input_dir / "processed_videos"
            if processed_videos_dir.exists():
                target_processed_videos_dir = archive_metadata_dir / "processed_videos"
                shutil.move(str(processed_videos_dir), str(target_processed_videos_dir))
        
        # åˆ›å»ºå½’æ¡£å…ƒæ•°æ®
        archive_metadata = {
            'archive_batch_id': archive_batch_id,
            'archive_time': datetime.now().isoformat(),
            'moved_files_count': moved_count,
            'source_directory': str(self.input_dir),
            'archive_directory': str(archive_batch_dir),
            'training_completed': True,
            'description': 'è®­ç»ƒå®Œæˆåå½’æ¡£çš„æ•°æ®'
        }
        
        metadata_file = archive_metadata_dir / "archive_info.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(archive_metadata, f, indent=2, ensure_ascii=False)
        
        # æ›´æ–°æ€»ä½“å½’æ¡£è®°å½•
        self._update_trained_data_index(archive_batch_id, archive_metadata)
        
        print(f"ğŸ“¦ å·²å½’æ¡£ {moved_count} ä¸ªæ–‡ä»¶åˆ°: {archive_batch_dir}")
        print(f"ğŸ“‹ å½’æ¡£å…ƒæ•°æ®å·²ä¿å­˜: {metadata_file}")
    
    def _update_trained_data_index(self, batch_id, metadata):
        """æ›´æ–°å·²è®­ç»ƒæ•°æ®ç´¢å¼•"""
        index_file = self.trained_data_dir / "trained_data_index.json"
        
        # è¯»å–ç°æœ‰ç´¢å¼•
        if index_file.exists():
            with open(index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
        else:
            index_data = {
                'total_batches': 0,
                'total_files': 0,
                'batches': []
            }
        
        # æ·»åŠ æ–°æ‰¹æ¬¡
        index_data['total_batches'] += 1
        index_data['total_files'] += metadata['moved_files_count']
        index_data['batches'].append({
            'batch_id': batch_id,
            'archive_time': metadata['archive_time'],
            'files_count': metadata['moved_files_count'],
            'batch_directory': f"batch_{batch_id}"
        })
        
        # ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š å·²è®­ç»ƒæ•°æ®ç´¢å¼•å·²æ›´æ–°: æ€»æ‰¹æ¬¡ {index_data['total_batches']}, æ€»æ–‡ä»¶ {index_data['total_files']}")
    
    def _cleanup_input_directory(self):
        """æ¸…ç†è®­ç»ƒè¾“å…¥ç›®å½•"""
        print("ğŸ§¹ æ£€æŸ¥è®­ç»ƒè¾“å…¥ç›®å½•æ¸…ç†çŠ¶æ€...")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å‰©ä½™æ–‡ä»¶
        remaining_files = []
        
        if self.input_dir.exists():
            # æ£€æŸ¥å›¾åƒæ–‡ä»¶
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
            for ext in image_extensions:
                remaining_files.extend(list(self.input_dir.glob(f"*{ext}")))
                remaining_files.extend(list(self.input_dir.glob(f"*{ext.upper()}")))
            
            # æ£€æŸ¥å­ç›®å½•
            images_subdir = self.input_dir / "images"
            if images_subdir.exists():
                for ext in image_extensions:
                    remaining_files.extend(list(images_subdir.glob(f"*{ext}")))
                    remaining_files.extend(list(images_subdir.glob(f"*{ext.upper()}")))
            
            # æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶
            annotation_extensions = ['.txt', '.json', '.xml']
            for ext in annotation_extensions:
                remaining_files.extend(list(self.input_dir.glob(f"*{ext}")))
            
            annotations_subdir = self.input_dir / "annotations"
            if annotations_subdir.exists():
                for ext in annotation_extensions:
                    remaining_files.extend(list(annotations_subdir.glob(f"*{ext}")))
        
        if remaining_files:
            print(f"âš ï¸ å‘ç° {len(remaining_files)} ä¸ªæœªå¤„ç†çš„æ–‡ä»¶")
            for file in remaining_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {file.name}")
            if len(remaining_files) > 5:
                print(f"   ... è¿˜æœ‰ {len(remaining_files) - 5} ä¸ªæ–‡ä»¶")
        else:
            print("âœ… è®­ç»ƒè¾“å…¥ç›®å½•å·²æ¸…ç†å®Œæˆï¼Œå¯ä»¥æ”¾å…¥æ–°çš„æ•°æ®")
            print(f"ğŸ“ å‡†å¤‡æ¥æ”¶æ–°æ•°æ®: {self.input_dir}")
    
    def _has_existing_data(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„è®­ç»ƒæ•°æ®"""
        train_images = list((self.processed_dir / "images" / "train").glob("*"))
        return len(train_images) > 0
    
    def _create_input_directory_guide(self):
        """åˆ›å»ºè¾“å…¥ç›®å½•ä½¿ç”¨æŒ‡å—"""
        guide_content = f"""
# ğŸŒï¸ é«˜å°”å¤«çƒæ†æ£€æµ‹è‡ªåŠ¨è®­ç»ƒç³»ç»Ÿä½¿ç”¨æŒ‡å—

## æ•°æ®æµç¨‹è¯´æ˜

### 1. è§†é¢‘æ ‡æ³¨é˜¶æ®µ
å°†è§†é¢‘æ–‡ä»¶æ”¾å…¥è§†é¢‘è¾“å…¥ç›®å½•ï¼š
```
C:\\Users\\Administrator\\Desktop\\AIGolf\\videos\\
â”œâ”€â”€ video1.mp4           # è§†é¢‘æ–‡ä»¶ (.mp4, .avi, .mov, .mkv, .wmv)
â”œâ”€â”€ video2.mp4
â””â”€â”€ video3.avi
```

è¿è¡Œè§†é¢‘æ ‡æ³¨ç³»ç»Ÿï¼š
```bash
cd yolo_dataset_full
python video_annotation_system.py --mode rotated_bbox --frame_interval 10 --max_frames 50
```

### 2. è®­ç»ƒæ•°æ®å‡†å¤‡
è§†é¢‘æ ‡æ³¨ç³»ç»Ÿä¼šè‡ªåŠ¨å°†æ ‡æ³¨ç»“æœè¾“å‡ºåˆ°è®­ç»ƒè¾“å…¥ç›®å½•ï¼š
```
{self.input_dir}/
â”œâ”€â”€ images/              # ä»è§†é¢‘æå–çš„å¸§å›¾åƒ
â”‚   â”œâ”€â”€ video1_frame_000001.jpg
â”‚   â”œâ”€â”€ video1_frame_000011.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ annotations/         # YOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶
â”‚   â”œâ”€â”€ video1_frame_000001.txt
â”‚   â”œâ”€â”€ video1_frame_000011.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ processed_videos/    # å·²å¤„ç†è§†é¢‘è®°å½•
    â””â”€â”€ processed_list.json
```

### 3. è‡ªåŠ¨è®­ç»ƒ
è¿è¡Œè®­ç»ƒè„šæœ¬ï¼š
```bash
cd yolo_dataset_full
python train_yolo_auto.py
```

### 4. ç³»ç»Ÿä¼šè‡ªåŠ¨å®Œæˆ
- âœ… æ£€æµ‹è®­ç»ƒè¾“å…¥ç›®å½•ä¸­çš„æ–°æ•°æ®
- âœ… è½¬æ¢æ ‡æ³¨æ ¼å¼ï¼ˆå¦‚éœ€è¦ï¼‰
- âœ… å»é™¤é‡å¤æ•°æ®
- âœ… åˆå¹¶åˆ°è®­ç»ƒé›†
- âœ… æ™ºèƒ½é€‰æ‹©è®­ç»ƒç­–ç•¥
- âœ… æ‰§è¡Œè®­ç»ƒ
- âœ… ä¿å­˜æ¨¡å‹
- âœ… å½’æ¡£å·²è®­ç»ƒæ•°æ®

### 5. æŸ¥çœ‹ç»“æœ
- æœ€æ–°æ¨¡å‹: `yolo_dataset_full/models/latest/best.pt`
- è®­ç»ƒæ—¥å¿—: `yolo_dataset_full/logs/`
- æ•°æ®å½’æ¡£: `yolo_dataset_full/archive/`
- å·²è®­ç»ƒæ•°æ®: `yolo_dataset_full/trained_data/`

### 6. æ•°æ®ç®¡ç†
è®­ç»ƒå®Œæˆåï¼Œå·²è®­ç»ƒçš„æ•°æ®ä¼šè‡ªåŠ¨ç§»åŠ¨åˆ° `trained_data` ç›®å½•ï¼š
```
yolo_dataset_full/trained_data/
â”œâ”€â”€ batch_20231201_143022/    # æŒ‰æ‰¹æ¬¡ç»„ç»‡
â”‚   â”œâ”€â”€ images/              # å·²è®­ç»ƒçš„å›¾åƒ
â”‚   â”œâ”€â”€ annotations/         # å·²è®­ç»ƒçš„æ ‡æ³¨
â”‚   â””â”€â”€ metadata/           # æ‰¹æ¬¡å…ƒæ•°æ®
â”œâ”€â”€ batch_20231202_091545/
â””â”€â”€ trained_data_index.json  # æ€»ä½“ç´¢å¼•
```

## å®Œæ•´å·¥ä½œæµç¨‹

1. **å‡†å¤‡è§†é¢‘**: å°†è§†é¢‘æ–‡ä»¶æ”¾å…¥ `C:\\Users\\Administrator\\Desktop\\AIGolf\\videos\\`
2. **è§†é¢‘æ ‡æ³¨**: è¿è¡Œ `python video_annotation_system.py`
3. **è‡ªåŠ¨è®­ç»ƒ**: è¿è¡Œ `python train_yolo_auto.py`
4. **æŸ¥çœ‹ç»“æœ**: æ£€æŸ¥ `models/latest/best.pt`
5. **ç»§ç»­è®­ç»ƒ**: æ·»åŠ æ–°è§†é¢‘ï¼Œé‡å¤æ­¥éª¤1-3

ç°åœ¨è¯·æŒ‰ç…§ä¸Šè¿°æµç¨‹æ“ä½œã€‚å¦‚æœè®­ç»ƒè¾“å…¥ç›®å½•ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œè§†é¢‘æ ‡æ³¨ç³»ç»Ÿã€‚
"""
        
        guide_file = self.base_dir / "ä½¿ç”¨æŒ‡å—.md"
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        print(f"ğŸ“– ä½¿ç”¨æŒ‡å—å·²åˆ›å»º: {guide_file}")
        print(f"è¯·æŒ‰ç…§æŒ‡å—æ“ä½œï¼š")
        print(f"1. å°†è§†é¢‘æ”¾å…¥: C:\\Users\\Administrator\\Desktop\\AIGolf\\videos\\")
        print(f"2. è¿è¡Œè§†é¢‘æ ‡æ³¨: python video_annotation_system.py")
        print(f"3. è¿è¡Œè®­ç»ƒ: python train_yolo_auto.py")
    
    def _log_step(self, step_name):
        """è®°å½•å¤„ç†æ­¥éª¤"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {step_name}"
        self.processing_log.append(log_entry)
        print(f"ğŸ”„ {step_name}...")
    
    def _handle_error(self, error):
        """å¤„ç†é”™è¯¯å¹¶ä¿å­˜æ—¥å¿—"""
        error_log = {
            'timestamp': datetime.now().isoformat(),
            'error': str(error),
            'traceback': traceback.format_exc(),
            'processing_log': self.processing_log
        }
        
        error_file = self.logs_dir / f"error_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(error_log, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°: {error_file}") 