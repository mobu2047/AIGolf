#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜å°”å¤«çƒæ†æ ‡æ³¨æ•°æ®å¯è§†åŒ–å·¥å…·
é€‚é…è§†é¢‘æ ‡æ³¨ç³»ç»Ÿè¾“å‡ºçš„æ•°æ®æ ¼å¼
æ”¯æŒYOLOæ ¼å¼æ ‡æ³¨å’ŒJSONè¯¦ç»†ä¿¡æ¯çš„å¯è§†åŒ–
"""

import os
import json
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pathlib import Path
import random
import argparse

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# å›ºå®šè·¯å¾„é…ç½®
DATASET_DIR = Path(r"C:\Users\Administrator\Desktop\AIGolf\dataset")

class AnnotationVisualizer:
    """æ ‡æ³¨æ•°æ®å¯è§†åŒ–å™¨"""
    
    def __init__(self, dataset_dir=None):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            dataset_dir: æ•°æ®é›†ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å›ºå®šè·¯å¾„
        """
        self.dataset_dir = Path(dataset_dir) if dataset_dir else DATASET_DIR
        self.images_dir = self.dataset_dir / "images"
        self.annotations_dir = self.dataset_dir / "annotations"
        
        print(f"ğŸ¯ æ ‡æ³¨æ•°æ®å¯è§†åŒ–å™¨å·²åˆå§‹åŒ–")
        print(f"ğŸ“ æ•°æ®é›†ç›®å½•: {self.dataset_dir.absolute()}")
        print(f"ğŸ“ å›¾åƒç›®å½•: {self.images_dir.absolute()}")
        print(f"ğŸ“ æ ‡æ³¨ç›®å½•: {self.annotations_dir.absolute()}")
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        self._check_directories()
    
    def _check_directories(self):
        """æ£€æŸ¥å¿…è¦ç›®å½•æ˜¯å¦å­˜åœ¨"""
        if not self.dataset_dir.exists():
            raise FileNotFoundError(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {self.dataset_dir}")
        
        if not self.images_dir.exists():
            raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {self.images_dir}")
        
        if not self.annotations_dir.exists():
            raise FileNotFoundError(f"æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {self.annotations_dir}")
    
    def get_image_files(self):
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(list(self.images_dir.glob(f"*{ext}")))
            image_files.extend(list(self.images_dir.glob(f"*{ext.upper()}")))
        
        return sorted(image_files)
    
    def load_yolo_annotation(self, image_path):
        """
        åŠ è½½YOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            list: YOLOæ ‡æ³¨åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º [class_id, x_center, y_center, width, height]
        """
        annotation_file = self.annotations_dir / f"{image_path.stem}.txt"
        
        if not annotation_file.exists():
            return []
        
        annotations = []
        try:
            with open(annotation_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) == 5:
                            class_id = int(parts[0])
                            x_center = float(parts[1])
                            y_center = float(parts[2])
                            width = float(parts[3])
                            height = float(parts[4])
                            annotations.append([class_id, x_center, y_center, width, height])
        except Exception as e:
            print(f"âš ï¸ è¯»å–YOLOæ ‡æ³¨æ–‡ä»¶å¤±è´¥ {annotation_file}: {e}")
        
        return annotations
    
    def load_detailed_annotation(self, image_path):
        """
        åŠ è½½è¯¦ç»†æ ‡æ³¨ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: è¯¦ç»†æ ‡æ³¨ä¿¡æ¯ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        detail_file = self.annotations_dir / f"{image_path.stem}_detail.json"
        
        if not detail_file.exists():
            return None
        
        try:
            with open(detail_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ è¯»å–è¯¦ç»†æ ‡æ³¨æ–‡ä»¶å¤±è´¥ {detail_file}: {e}")
            return None
    
    def yolo_to_bbox(self, yolo_annotation, img_width, img_height):
        """
        å°†YOLOæ ¼å¼åæ ‡è½¬æ¢ä¸ºè¾¹ç•Œæ¡†åæ ‡
        
        Args:
            yolo_annotation: [class_id, x_center, y_center, width, height] (å½’ä¸€åŒ–åæ ‡)
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
            
        Returns:
            tuple: (x, y, w, h) åƒç´ åæ ‡
        """
        class_id, x_center, y_center, width, height = yolo_annotation
        
        # è½¬æ¢ä¸ºåƒç´ åæ ‡
        x_center_px = x_center * img_width
        y_center_px = y_center * img_height
        width_px = width * img_width
        height_px = height * img_height
        
        # è®¡ç®—å·¦ä¸Šè§’åæ ‡
        x = x_center_px - width_px / 2
        y = y_center_px - height_px / 2
        
        return (x, y, width_px, height_px)
    
    def visualize_single_image(self, image_path, save_path=None, show_details=True):
        """
        å¯è§†åŒ–å•ä¸ªå›¾åƒåŠå…¶æ ‡æ³¨
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None
        
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_height, img_width = image.shape[:2]
        
        # åŠ è½½æ ‡æ³¨æ•°æ®
        yolo_annotations = self.load_yolo_annotation(image_path)
        detailed_annotation = self.load_detailed_annotation(image_path)
        
        print(f"\n=== å›¾åƒä¿¡æ¯ ===")
        print(f"ğŸ“ æ–‡ä»¶å: {image_path.name}")
        print(f"ğŸ“ å°ºå¯¸: {img_width} x {img_height}")
        print(f"ğŸ“ YOLOæ ‡æ³¨æ•°é‡: {len(yolo_annotations)}")
        print(f"ğŸ“‹ è¯¦ç»†æ ‡æ³¨: {'æœ‰' if detailed_annotation else 'æ— '}")
        
        # åˆ›å»ºmatplotlibå›¾å½¢
        fig, ax = plt.subplots(1, 1, figsize=(12, 16))
        
        # æ˜¾ç¤ºå›¾åƒ
        ax.imshow(image_rgb)
        title = f'é«˜å°”å¤«çƒæ†æ ‡æ³¨ - {image_path.name}'
        if len(yolo_annotations) > 0:
            title += f'\n(å…±{len(yolo_annotations)}ä¸ªæ ‡æ³¨)'
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.axis('off')
        
        # ç»˜åˆ¶æ ‡æ³¨
        colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange']
        
        # ä¼˜å…ˆä½¿ç”¨è¯¦ç»†æ ‡æ³¨ä¿¡æ¯ç»˜åˆ¶æ—‹è½¬è¾¹ç•Œæ¡†
        if detailed_annotation and 'rotated_corners' in detailed_annotation:
            self._draw_rotated_bbox(ax, detailed_annotation, colors[0])
            
            if show_details:
                self._show_detailed_info(detailed_annotation)
        
        # ç»˜åˆ¶YOLOæ ‡æ³¨ï¼ˆè½´å¯¹é½è¾¹ç•Œæ¡†ï¼‰
        for i, yolo_ann in enumerate(yolo_annotations):
            color = colors[i % len(colors)]
            x, y, w, h = self.yolo_to_bbox(yolo_ann, img_width, img_height)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            rect = patches.Rectangle((x, y), w, h, 
                                   linewidth=3, 
                                   edgecolor=color, 
                                   facecolor=color,
                                   alpha=0.3)
            ax.add_patch(rect)
            
            # ç»˜åˆ¶è¾¹æ¡†è½®å»“
            rect_outline = patches.Rectangle((x, y), w, h, 
                                           linewidth=3, 
                                           edgecolor=color, 
                                           facecolor='none',
                                           alpha=0.9)
            ax.add_patch(rect_outline)
            
            # æ·»åŠ æ ‡ç­¾
            class_id = int(yolo_ann[0])
            class_name = "çƒæ†" if class_id == 0 else f"ç±»åˆ«{class_id}"
            
            ax.text(x + w/2, y - 20, f'{class_name} #{i+1}', 
                    fontsize=12, 
                    color='white', 
                    weight='bold',
                    ha='center',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor=color, alpha=0.8))
            
            print(f"  ğŸ“¦ YOLOæ ‡æ³¨ {i+1}: ç±»åˆ«={class_id}, è¾¹ç•Œæ¡†=({x:.1f}, {y:.1f}, {w:.1f}, {h:.1f})")
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        return fig
    
    def _draw_rotated_bbox(self, ax, detailed_annotation, color):
        """ç»˜åˆ¶æ—‹è½¬è¾¹ç•Œæ¡†"""
        if 'rotated_corners' not in detailed_annotation:
            return
        
        rotated_corners = detailed_annotation['rotated_corners']
        
        # åˆ›å»ºå¤šè¾¹å½¢å¡«å……
        polygon = patches.Polygon(rotated_corners, 
                                linewidth=3, 
                                edgecolor=color, 
                                facecolor=color,
                                alpha=0.3)
        ax.add_patch(polygon)
        
        # ç»˜åˆ¶è¾¹æ¡†
        polygon_outline = patches.Polygon(rotated_corners, 
                                        linewidth=3, 
                                        edgecolor=color, 
                                        facecolor='none',
                                        alpha=0.9)
        ax.add_patch(polygon_outline)
        
        # è®¡ç®—ä¸­å¿ƒç‚¹ç”¨äºæ”¾ç½®æ ‡ç­¾
        center_x = np.mean([corner[0] for corner in rotated_corners])
        center_y = np.mean([corner[1] for corner in rotated_corners])
        
        # æ·»åŠ æ ‡ç­¾
        ax.text(center_x, center_y-30, 'æ—‹è½¬è¾¹ç•Œæ¡†', 
                fontsize=12, 
                color='white', 
                weight='bold',
                ha='center',
                bbox=dict(boxstyle="round,pad=0.5", facecolor=color, alpha=0.8))
        
        # ç»˜åˆ¶çƒæ†ä¸­å¿ƒçº¿ï¼ˆå¦‚æœæœ‰ç«¯ç‚¹ä¿¡æ¯ï¼‰
        if 'points' in detailed_annotation:
            points = detailed_annotation['points']
            if len(points) == 2:
                point1, point2 = points
                ax.plot([point1[0], point2[0]], [point1[1], point2[1]], 
                       color='white', linewidth=4, alpha=0.8)
                ax.plot([point1[0], point2[0]], [point1[1], point2[1]], 
                       color=color, linewidth=2, alpha=1.0)
                
                # æ ‡è®°ç«¯ç‚¹
                ax.plot(point1[0], point1[1], 'o', color='white', markersize=8)
                ax.plot(point1[0], point1[1], 'o', color=color, markersize=6)
                ax.plot(point2[0], point2[1], 'o', color='white', markersize=8)
                ax.plot(point2[0], point2[1], 'o', color=color, markersize=6)
    
    def _show_detailed_info(self, detailed_annotation):
        """æ˜¾ç¤ºè¯¦ç»†æ ‡æ³¨ä¿¡æ¯"""
        print(f"  ğŸ” è¯¦ç»†æ ‡æ³¨ä¿¡æ¯:")
        print(f"    ğŸ“ æ ‡æ³¨æ¨¡å¼: {detailed_annotation.get('mode', 'unknown')}")
        
        if 'points' in detailed_annotation:
            points = detailed_annotation['points']
            print(f"    ğŸ“ çƒæ†ç«¯ç‚¹: {points}")
        
        if 'length' in detailed_annotation:
            print(f"    ğŸ“ çƒæ†é•¿åº¦: {detailed_annotation['length']:.1f}px")
        
        if 'angle' in detailed_annotation:
            print(f"    ğŸ“ çƒæ†è§’åº¦: {detailed_annotation['angle']:.1f}Â°")
        
        if 'club_width' in detailed_annotation:
            print(f"    ğŸ“ çƒæ†å®½åº¦: {detailed_annotation['club_width']:.1f}px")
        
        if 'rotated_area' in detailed_annotation:
            print(f"    ğŸ“Š æ—‹è½¬è¾¹ç•Œæ¡†é¢ç§¯: {detailed_annotation['rotated_area']:.1f}pxÂ²")
        
        if 'frame_info' in detailed_annotation:
            frame_info = detailed_annotation['frame_info']
            print(f"    ğŸ¬ è§†é¢‘ä¿¡æ¯:")
            print(f"      è§†é¢‘åç§°: {frame_info.get('video_name', 'unknown')}")
            print(f"      å¸§ç´¢å¼•: {frame_info.get('frame_index', 'unknown')}")
            print(f"      æ—¶é—´æˆ³: {frame_info.get('timestamp', 'unknown'):.2f}s")
    
    def visualize_multiple_samples(self, num_samples=20, save_dir="visualization_samples"):
        """
        å¯è§†åŒ–å¤šä¸ªæ ·æœ¬
        
        Args:
            num_samples: è¦å¯è§†åŒ–çš„æ ·æœ¬æ•°é‡
            save_dir: ä¿å­˜ç›®å½•
        """
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True)
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files()
        
        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼")
            return
        
        # ç­›é€‰æœ‰æ ‡æ³¨çš„å›¾åƒ
        images_with_annotations = []
        for img_path in image_files:
            yolo_annotations = self.load_yolo_annotation(img_path)
            if yolo_annotations:
                images_with_annotations.append(img_path)
        
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»å›¾åƒæ•°: {len(image_files)}")
        print(f"  æœ‰æ ‡æ³¨çš„å›¾åƒæ•°: {len(images_with_annotations)}")
        print(f"  æ— æ ‡æ³¨çš„å›¾åƒæ•°: {len(image_files) - len(images_with_annotations)}")
        
        if not images_with_annotations:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ ‡æ³¨çš„å›¾åƒï¼")
            return
        
        # éšæœºé€‰æ‹©æ ·æœ¬
        selected_images = random.sample(images_with_annotations, 
                                      min(num_samples, len(images_with_annotations)))
        
        print(f"ğŸ¯ éšæœºé€‰æ‹© {len(selected_images)} å¼ å›¾åƒè¿›è¡Œå¯è§†åŒ–")
        
        for i, image_path in enumerate(selected_images):
            print(f"\n{'='*60}")
            print(f"ğŸ“¸ å¯è§†åŒ–æ ·æœ¬ {i+1}/{len(selected_images)}")
            
            save_path = save_dir / f"sample_{i+1:03d}_{image_path.stem}.png"
            self.visualize_single_image(image_path, save_path, show_details=True)
    
    def analyze_dataset_statistics(self):
        """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*60}")
        print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡åˆ†æ")
        print(f"{'='*60}")
        
        image_files = self.get_image_files()
        
        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼")
            return
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_images = len(image_files)
        images_with_yolo = 0
        images_with_detail = 0
        total_annotations = 0
        
        annotation_modes = {}
        video_sources = {}
        bbox_areas = []
        club_lengths = []
        club_angles = []
        
        for img_path in image_files:
            # æ£€æŸ¥YOLOæ ‡æ³¨
            yolo_annotations = self.load_yolo_annotation(img_path)
            if yolo_annotations:
                images_with_yolo += 1
                total_annotations += len(yolo_annotations)
                
                # è®¡ç®—è¾¹ç•Œæ¡†é¢ç§¯
                image = cv2.imread(str(img_path))
                if image is not None:
                    img_height, img_width = image.shape[:2]
                    for yolo_ann in yolo_annotations:
                        x, y, w, h = self.yolo_to_bbox(yolo_ann, img_width, img_height)
                        bbox_areas.append(w * h)
            
            # æ£€æŸ¥è¯¦ç»†æ ‡æ³¨
            detailed_annotation = self.load_detailed_annotation(img_path)
            if detailed_annotation:
                images_with_detail += 1
                
                # ç»Ÿè®¡æ ‡æ³¨æ¨¡å¼
                mode = detailed_annotation.get('mode', 'unknown')
                annotation_modes[mode] = annotation_modes.get(mode, 0) + 1
                
                # ç»Ÿè®¡è§†é¢‘æ¥æº
                frame_info = detailed_annotation.get('frame_info', {})
                video_name = frame_info.get('video_name', 'unknown')
                video_sources[video_name] = video_sources.get(video_name, 0) + 1
                
                # æ”¶é›†çƒæ†ä¿¡æ¯
                if 'length' in detailed_annotation:
                    club_lengths.append(detailed_annotation['length'])
                if 'angle' in detailed_annotation:
                    club_angles.append(detailed_annotation['angle'])
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        print(f"ğŸ“ æ€»å›¾åƒæ•°: {total_images}")
        print(f"ğŸ“ æœ‰YOLOæ ‡æ³¨çš„å›¾åƒ: {images_with_yolo}")
        print(f"ğŸ“‹ æœ‰è¯¦ç»†æ ‡æ³¨çš„å›¾åƒ: {images_with_detail}")
        print(f"ğŸ“Š æ€»æ ‡æ³¨æ•°: {total_annotations}")
        
        if images_with_yolo > 0:
            print(f"ğŸ“ˆ å¹³å‡æ¯å¼ å›¾åƒæ ‡æ³¨æ•°: {total_annotations / images_with_yolo:.2f}")
        
        # æ ‡æ³¨æ¨¡å¼åˆ†å¸ƒ
        if annotation_modes:
            print(f"\nğŸ“ æ ‡æ³¨æ¨¡å¼åˆ†å¸ƒ:")
            for mode, count in annotation_modes.items():
                print(f"  {mode}: {count} ä¸ª")
        
        # è§†é¢‘æ¥æºåˆ†å¸ƒ
        if video_sources:
            print(f"\nğŸ¬ è§†é¢‘æ¥æºåˆ†å¸ƒ:")
            for video, count in sorted(video_sources.items()):
                print(f"  {video}: {count} å¸§")
        
        # è¾¹ç•Œæ¡†ç»Ÿè®¡
        if bbox_areas:
            print(f"\nğŸ“¦ è¾¹ç•Œæ¡†é¢ç§¯ç»Ÿè®¡:")
            print(f"  æœ€å°é¢ç§¯: {min(bbox_areas):.1f}pxÂ²")
            print(f"  æœ€å¤§é¢ç§¯: {max(bbox_areas):.1f}pxÂ²")
            print(f"  å¹³å‡é¢ç§¯: {np.mean(bbox_areas):.1f}pxÂ²")
            print(f"  ä¸­ä½æ•°é¢ç§¯: {np.median(bbox_areas):.1f}pxÂ²")
        
        # çƒæ†é•¿åº¦ç»Ÿè®¡
        if club_lengths:
            print(f"\nğŸ“ çƒæ†é•¿åº¦ç»Ÿè®¡:")
            print(f"  æœ€çŸ­é•¿åº¦: {min(club_lengths):.1f}px")
            print(f"  æœ€é•¿é•¿åº¦: {max(club_lengths):.1f}px")
            print(f"  å¹³å‡é•¿åº¦: {np.mean(club_lengths):.1f}px")
        
        # çƒæ†è§’åº¦ç»Ÿè®¡
        if club_angles:
            print(f"\nğŸ“ çƒæ†è§’åº¦ç»Ÿè®¡:")
            print(f"  è§’åº¦èŒƒå›´: {min(club_angles):.1f}Â° - {max(club_angles):.1f}Â°")
            print(f"  å¹³å‡è§’åº¦: {np.mean(club_angles):.1f}Â°")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é«˜å°”å¤«çƒæ†æ ‡æ³¨æ•°æ®å¯è§†åŒ–å·¥å…·")
    parser.add_argument("--dataset_dir", "-d", type=str, 
                       help="æ•°æ®é›†ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨å›ºå®šè·¯å¾„ï¼‰")
    parser.add_argument("--num_samples", "-n", type=int, default=20, 
                       help="å¯è§†åŒ–æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤20ï¼‰")
    parser.add_argument("--save_dir", "-s", type=str, default="visualization_samples", 
                       help="ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤visualization_samplesï¼‰")
    parser.add_argument("--single_image", "-i", type=str, 
                       help="å¯è§†åŒ–å•ä¸ªå›¾åƒï¼ˆæŒ‡å®šå›¾åƒæ–‡ä»¶åï¼‰")
    parser.add_argument("--stats_only", action="store_true", 
                       help="ä»…æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œä¸è¿›è¡Œå¯è§†åŒ–")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = AnnotationVisualizer(args.dataset_dir)
        
        print("ğŸŒï¸ é«˜å°”å¤«çƒæ†æ ‡æ³¨æ•°æ®å¯è§†åŒ–å·¥å…·")
        print("="*60)
        
        # åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        visualizer.analyze_dataset_statistics()
        
        if args.stats_only:
            print("\nâœ… ç»Ÿè®¡åˆ†æå®Œæˆï¼")
            return
        
        if args.single_image:
            # å¯è§†åŒ–å•ä¸ªå›¾åƒ
            image_path = visualizer.images_dir / args.single_image
            if image_path.exists():
                print(f"\n{'='*60}")
                print(f"ğŸ“¸ å¯è§†åŒ–å•ä¸ªå›¾åƒ: {args.single_image}")
                visualizer.visualize_single_image(image_path, show_details=True)
            else:
                print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        else:
            # å¯è§†åŒ–å¤šä¸ªæ ·æœ¬
            print(f"\n{'='*60}")
            print("ğŸ“¸ å¼€å§‹æ‰¹é‡å¯è§†åŒ–...")
            visualizer.visualize_multiple_samples(args.num_samples, args.save_dir)
            
            print(f"\n{'='*60}")
            print("âœ… å¯è§†åŒ–å®Œæˆï¼")
            print(f"ğŸ“ å¯ä»¥åœ¨ '{args.save_dir}' ç›®å½•ä¸­æŸ¥çœ‹ä¿å­˜çš„å›¾åƒ")
    
    except Exception as e:
        print(f"âŒ è¿è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 